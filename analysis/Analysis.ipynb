{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the analysis consist of wrangling with data till will get the final form.\n",
    "This notebook has the functions which go in the database and aggregate needed columns\n",
    "\n",
    "These are the columns and a little explanation for each one\n",
    "\n",
    "1. **ID** - ego unique identification\n",
    "2. **EGO_COUNTRY** - country of current affiliation of ego\n",
    "3. **EGO_PAPERS** - total number of ego publications *(to be noted, data was scraped in september 2018 - january 2019, Scopus keep indexing documents, from later and former years)*\n",
    "4. **EGO_CITATIONS** - total number of ego citations, *same note as above*\n",
    "5. **EGO_COAUTHORS** - total number of authors in ego network\n",
    "6. **EGO_EDGES** - unique collaboration with each author in each year, if ego did wrote in 2010 and 2011 with same author 5 documents, will be counted as 2, (2010 and 2011)\n",
    "7. **ALTER_DOMESTIC** - how many authors have same affiliation country as ego\n",
    "8. **ALTER_NONDOMESTIC** - how many authors does not have same affiliation country as ego\n",
    "9. **ALTER_CITATIONS** - cumulated sum of coauthors citations\n",
    "10. **ALTER_PAPERS** - cumulated sum of coauthors articles (with or without ego)\n",
    "11. **ALTER_EGO_PAPERS** - how many articles did ego wrote with his coauthors\n",
    "12. **ALTER_EGO_CITATIONS** - to be excluded (not all articles does have citations)\n",
    "13. **ALTER_COUNTRY** - number of different nondomestic countries\n",
    "14. **ALTER_COUNTRIES** - list of nondomestic countries\n",
    "15. **ALTER_MAX_PAPERS** - the author from ego network which has most papers\n",
    "16. **ALTER_MAX_CITATIONS** - the author from ego network which has most citations\n",
    "17. **EGO_BETWEENES** - centrality score of ego in his network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SQLContext, Row, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from parquet files, which were saved from the sqlite database using `to_parquet.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = sqlContext.read.parquet('./data/authors')\n",
    "collaborations = sqlContext.read.parquet('./data/collaborations')\n",
    "collaborations = collaborations.withColumn('published', F.to_date(F.col('published')))\n",
    "collaborations = collaborations.withColumn('year', F.year(F.col('published')))\n",
    "collaborations = collaborations.withColumnRenamed('author_id', 'auth_id')\n",
    "collaborations = collaborations.withColumn('auth_id', collaborations.auth_id.cast('bigint'))\n",
    "ego_alters = sqlContext.read.parquet('./data/ego_alters')\n",
    "# Compute authors citations based on downloaded papers\n",
    "# Because not all articles for authors were scraped we need to base our analysis on grounded data, not missing\n",
    "authors = authors.join(collaborations, collaborations.auth_id == authors.id, 'INNER') \\\n",
    "        .groupby([authors.id]) \\\n",
    "        .agg( \\\n",
    "            F.count('abs_id').alias('PAPERS'), \\\n",
    "            F.first('cited_by_count').alias('CITATIONS_SCOPUS'), \\\n",
    "            F.sum('cited_by').alias('CITATIONS'), \\\n",
    "            F.first('cat').alias('cat'), \\\n",
    "            F.first('university').alias('university'), \\\n",
    "            F.first('city').alias('city'), \\\n",
    "            F.first('country').alias('country'))\n",
    "# Exclude articles which have errors\n",
    "collaborations = collaborations.filter(collaborations.abs_id != 85032509284)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for most citated authors on PHYS category from UE and get the EGOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['Austria', 'Belgium', 'Bulgaria', 'Croatia', 'Cyprus', 'Czech Republic', \n",
    "             'Denmark', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', \n",
    "             'Ireland', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg', 'Malta', 'Netherlands',\n",
    "             'Poland', 'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'United Kingdom']\n",
    "\n",
    "most_cited_phys = authors.orderBy(F.col('CITATIONS').desc()) \\\n",
    "    .filter(F.col('country').isin(countries)) \\\n",
    "    .filter(F.col('cat').like('%PHYS%')) \\\n",
    "    .limit(1200) \\\n",
    "    .select( \\\n",
    "        authors.id.alias('EGO_ID'), \\\n",
    "        authors.country.alias('EGO_COUNTRY'), \\\n",
    "        authors['PAPERS'].alias('EGO_PAPERS'), \\\n",
    "        authors['CITATIONS'].alias('EGO_CITATIONS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the coauthors of each ego\n",
    "- First get ego collaborations\n",
    "- Then get authors of collaborations and exclude duplicate articles of ego\n",
    "- Obtain data about coauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select each ego articles \n",
    "most_cited_phys_coauthors = most_cited_phys.join(collaborations, F.col('EGO_ID') == collaborations.auth_id.alias('todel1'), 'inner')\n",
    "most_cited_phys_coauthors = most_cited_phys_coauthors.select('EGO_ID', 'EGO_COUNTRY', 'EGO_PAPERS', 'EGO_CITATIONS', F.col('abs_id').alias('coll_id'))\n",
    "\n",
    "# Based on ego articles select his coauthors\n",
    "most_cited_phys_coauthors = most_cited_phys_coauthors \\\n",
    "    .join(collaborations, most_cited_phys_coauthors.coll_id == collaborations.abs_id, 'INNER') \\\n",
    "    .filter(F.col('EGO_ID') != F.col('auth_id'))\n",
    "\n",
    "# And keep only columns which interest us\n",
    "most_cited_phys_coauthors = most_cited_phys_coauthors.select('EGO_ID', 'EGO_COUNTRY', 'EGO_PAPERS', 'EGO_CITATIONS', F.col('auth_id').alias('coauthor_id')) \\\n",
    "\n",
    "most_cited_phys_coauthors = most_cited_phys_coauthors.join(authors, most_cited_phys_coauthors.coauthor_id == authors['ID'], 'LEFT') \\\n",
    "    .select( \\\n",
    "        'EGO_ID', \\\n",
    "        'EGO_COUNTRY', \\\n",
    "        'EGO_PAPERS', \\\n",
    "        'EGO_CITATIONS', \\\n",
    "        'coauthor_id', \\\n",
    "        F.col('country').alias('coauthor_country'), \\\n",
    "        F.col('CITATIONS').alias('coauthor_citations'), \\\n",
    "        F.col('PAPERS').alias('coauthor_papers'))\n",
    "\n",
    "\n",
    "# Set coauthor type (domestic, non-domestic)\n",
    "def check_provenance(ego_c, alter_c):\n",
    "        if ego_c == alter_c:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "provenance = F.udf(check_provenance, IntegerType())\n",
    "most_cited_phys_coauthors = most_cited_phys_coauthors.withColumn('coauthor_domestic', provenance('EGO_COUNTRY', 'coauthor_country'))\n",
    "\n",
    "most_cited_phys_coauthors = most_cited_phys_coauthors.groupby(['EGO_ID']) \\\n",
    "    .agg( \\\n",
    "        F.first('EGO_COUNTRY').alias('EGO_COUNTRY'), \\\n",
    "        F.first('EGO_PAPERS').alias('EGO_PAPERS'), \\\n",
    "        F.first('EGO_CITATIONS').alias('EGO_CITATIONS'), \\\n",
    "        F.countDistinct('coauthor_id').alias('EGO_COAUTHORS'), \\\n",
    "        F.count('coauthor_id').alias('EGO_EDGES'), \\\n",
    "        F.countDistinct('coauthor_country').alias('ALTER_COUNTRY'), \\\n",
    "        F.collect_set('coauthor_country').alias('ALTER_COUNTRIES'), \\\n",
    "        F.max('coauthor_papers').alias('ALTER_MAX_PAPERS'), \\\n",
    "        F.max('coauthor_citations').alias('ALTER_MAX_CITATIONS'), \\\n",
    "        F.count(F.when(F.col('coauthor_domestic') == 1, True)).alias('ALTER_DOMESTIC'), \\\n",
    "        F.count(F.when(F.col('coauthor_domestic') == 0, True)).alias('ALTER_NONDOMESTIC'), \\\n",
    "    )\n",
    "\n",
    "most_cited_phys_coauthors.toPandas().to_csv('./baza_de_date_fizica.csv')\n",
    "\n",
    "# Show missing data\n",
    "# most_cited_phys_coauthors.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in most_cited_phys_coauthors.columns]).show()\n",
    "# Save missing authors ids\n",
    "# missing_coauth = most_cited_phys_coauthors.filter(F.isnan('coauthor_country') | F.col('coauthor_country').isNull()) \\\n",
    "#    .groupby(F.col('coauthor_id')).count().toPandas()\n",
    "# missing_coauth.to_csv('./missing_coauthors_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code down from here should be organized and explain, feel free to test it or add comments\n",
    "This function does build network of each ego and saves it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.99528000000004, 1.5212100000000532]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For further analysis we will extract location of each research and show a heatmap of authors\n",
    "#location_authors = authors.select(F.concat(F.col('university'), F.lit(','), F.col('city'), F.lit(','), F.col('country')).alias('location')).groupby(F.col('location')).count().toPandas()\n",
    "#location_authors.to_csv('./authors_location.csv')\n",
    "\n",
    "test = \"CONSORCI CENTRE DE CIENCIA I TECNOLOGIA FORESTAL DE CATALUNYA,Solsona,Spain\"\n",
    "import geocoder\n",
    "\n",
    "geocoder.arcgis(test).latlng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ego_alters():\n",
    "    publications = collaborations.filter(collaborations.auth_id.isin(list(networks.index))).select(collaborations.auth_id.alias('ego_id'),collaborations.abs_id.alias('todel1'))\n",
    "    alter_publications = publications.join(collaborations, publications.todel1 == collaborations.abs_id, 'inner')\n",
    "    ego_alters = alter_publications.dropDuplicates(['ego_id', 'auth_id']).groupby([alter_publications.ego_id, alter_publications.auth_id]).count() \n",
    "    # alter_publications.show(20)\n",
    "    # ego_alters.write.parquet('./data/ego_alters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look how much missing data there is in collaboration papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+-------+----+\n",
      "|abs_id|cited_by|keywords|auth_id|year|\n",
      "+------+--------+--------+-------+----+\n",
      "|     0|     162|12900432|      0| 280|\n",
      "+------+--------+--------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authors_cits = authors.join(collaborations, collaborations.auth_id == authors.id, 'inner') \\\n",
    "    .groupby([authors.id]) \\\n",
    "    .agg(F.sum(collaborations.cited_by).alias('cited_by_count2'))\n",
    "\n",
    "#authors_cits.show(20)\n",
    "collaborations.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in collaborations.columns if c != 'published']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ego_papers():\n",
    "    papers = authors.filter(authors.id.isin(list(networks.index))).join(collaborations, collaborations.auth_id == authors.id.alias('ID'), 'left') \\\n",
    "        .groupby([authors.id.alias('ID')]).agg(F.count('abs_id').alias('EGO_PAPERS2'))\n",
    "    to_p = papers.toPandas()\n",
    "    to_p['ID'] = to_p['ID'].astype(str)\n",
    "    return to_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get authors with missing countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alters_data = ego_alters.join(authors, ego_alters.auth_id == authors.id, 'left')\n",
    "missing_country = alters_data.filter(alters_data.country.isNull()).groupby(alters_data.auth_id).count().toPandas()\n",
    "missing_country.to_csv('./missing_country_phys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_provenance():\n",
    "    alters_country = ego_alters.join(authors, ego_alters.auth_id == authors.id).select(F.col('ego_id'), F.col('auth_id'), F.col('country').alias('alter_country'))\n",
    "    alters_country = alters_country.join(authors, alters_country.ego_id == authors.id).select(F.col('ego_id'),F.col('country').alias('ego_country'), F.col('alter_country'), F.col('auth_id'))\n",
    "\n",
    "    def check_provenance(ego_c, alter_c):\n",
    "        if ego_c == alter_c:\n",
    "            return 'domestic'\n",
    "        else:\n",
    "            return 'nondomestic'\n",
    "\n",
    "    provenance = F.udf(check_provenance, StringType())\n",
    "\n",
    "    alters_country = alters_country.withColumn('provenance', provenance('ego_country', 'alter_country'))\n",
    "\n",
    "    alters_country_provenance = alters_country.groupby('ego_id').pivot('provenance', ['domestic', 'nondomestic']).count()\n",
    "    alters_country_provenance = alters_country_provenance.withColumnRenamed('ego_id', 'ID')\n",
    "    alters_country_provenance = alters_country_provenance.withColumnRenamed('domestic', 'ALTER_DOMESTIC')\n",
    "    alters_country_provenance = alters_country_provenance.withColumnRenamed('nondomestic', 'ALTER_NONDOMESTIC')\n",
    "    \n",
    "    to_p = alters_country_provenance.toPandas()\n",
    "    to_p['ID'] = to_p['ID'].astype(str)\n",
    "    return to_p\n",
    "\n",
    "\n",
    "def alter_countries():\n",
    "    alters_country = ego_alters.join(authors, ego_alters.auth_id == authors.id).select(F.col('ego_id'), F.col('auth_id'), F.col('country').alias('alter_country'))\n",
    "    alters_country = alters_country.join(authors, alters_country.ego_id == authors.id).select(F.col('ego_id'),F.col('country').alias('ego_country'), F.col('alter_country'), F.col('auth_id'))\n",
    "\n",
    "    countries = alters_country.groupby('ego_id').agg(F.first('ego_country').alias('ego_country'),F.collect_set('alter_country').alias('ALTER_COUNTRIES'))\n",
    "    countries = countries.withColumnRenamed('ego_id', 'ID')\n",
    "    \n",
    "    to_p = countries.toPandas()\n",
    "    to_p['ID'] = to_p['ID'].astype(str)\n",
    "    \n",
    "    def map_alter_countries(row):\n",
    "        l = list(row['ALTER_COUNTRIES'])\n",
    "        l = [li for li in l if li != row['ego_country']]\n",
    "        return ','.join(l)\n",
    "    \n",
    "    def count_alter_countries(row):\n",
    "        l = list(row['ALTER_COUNTRIES'])\n",
    "        l = [li for li in l if li != row['ego_country']]\n",
    "        return len(l)\n",
    "        \n",
    "    to_p['ALTER_COUNTRIES'] = to_p.apply(lambda row: map_alter_countries(row), axis=1)\n",
    "    to_p['ALTER_COUNTRY'] = to_p.apply(lambda row: count_alter_countries(row), axis=1)\n",
    "    to_p.drop(['ego_country'], axis=1, inplace=True)\n",
    "    return to_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = networks.combine_first(alter_provenance().set_index('ID'))\n",
    "networks = networks.combine_first(alter_countries().set_index('ID'))\n",
    "networks.to_excel('./baza_date_fizica_temp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
